{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code to convert a string of Japanese text into a katakana version of that text with accent annotation. It does so by processing the text in the following series of steps.\n",
    "1. Perform morphological analysis using the dictionary unidic to obtain a list of tokens with pronunciation and accent information for each token.\n",
    "2. Compile XML trees for each sentence in the list of tokens.\n",
    "3. Run the sentence XML trees through XLS transformations using the ChaOne XLS files.\n",
    "4. Extract the accent phrases from the transformed XML trees as ordinary strings and add characters to those strings to denote pitch accent based on the transformed XML trees.\n",
    "\n",
    "Acknowledgements:\n",
    "unidic: dictionary for morphological analysis\n",
    "mecab: morphological analyzer\n",
    "fugashi: Python library for morphological analysis using mecab\n",
    "ChaOne: morpheme token combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fugashi\n",
    "from lxml import etree\n",
    "from typing import List\n",
    "import csv\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnidicFeaturesUnk = collections.namedtuple('UnidicFeaturesUnk', ['pos1', 'pos2', 'pos3', 'pos4', 'cType', 'cForm'])\n",
    "\n",
    "def annotate_accent (japanese_text: str) -> str:\n",
    "    assert(isinstance(japanese_text, str))\n",
    "    \n",
    "    #run morphological analysis on input string\n",
    "    tagger = fugashi.Tagger()\n",
    "    words = tagger(japanese_text)\n",
    "    \n",
    "    #convert list of tagged tokens to xml tree\n",
    "    xml_tree = tagger_output_to_xml(words)\n",
    "    \n",
    "    #run phonological processes on morphemes in xml_tree\n",
    "    ChaOne = etree.XSLT(etree.parse('./chaone-1.3.0b2/chaone_t_main.xsl'))\n",
    "    transformed_tree = ChaOne(xml_tree)\n",
    "    \n",
    "    #use tranformed xml tree to construct an annotated string\n",
    "    annotated_string = transformed_tree_to_annotated_kana(transformed_tree)\n",
    "    return annotated_string\n",
    "\n",
    "def annotate_accent_nbest(japanese_text: str, num: int = 3) -> List[str]:\n",
    "    assert(isinstance(japanese_text, str))\n",
    "    \n",
    "    #run morphological analysis on input string\n",
    "    tagger = fugashi.Tagger()\n",
    "    parsings_as_raw_output_strings = tagger.nbest(japanese_text, num).strip().split('EOS')\n",
    "    annotated_strings = []\n",
    "    \n",
    "    for parsing in parsings_as_raw_output_strings:\n",
    "        if parsing != '':\n",
    "            #convert list of tagged tokens to xml tree\n",
    "            xml_tree = raw_tagger_output_to_xml(parsing)\n",
    "    \n",
    "            #run phonological processes on morphemes in xml_tree\n",
    "            ChaOne = etree.XSLT(etree.parse('./chaone-1.3.0b2/chaone_t_main.xsl'))\n",
    "            transformed_tree = ChaOne(xml_tree)\n",
    "    \n",
    "            #use tranformed xml tree to construct an annotated string\n",
    "            annotated_strings.append(transformed_tree_to_annotated_kana(transformed_tree))\n",
    "\n",
    "    return annotated_strings\n",
    "\n",
    "def raw_tagger_output_to_xml(parsing):\n",
    "    xml_tree = etree.Element('S')\n",
    "    words = parsing.strip().splitlines()\n",
    "    print(words)\n",
    "    for word in words:\n",
    "        surface, features = word.split('\\t')\n",
    "        feature_list = next(csv.reader([features]))\n",
    "        if len(feature_list) > 6:\n",
    "            is_unk = False\n",
    "            feature_tuple = fugashi.UnidicFeatures29(*feature_list)\n",
    "        else:\n",
    "            is_unk = True\n",
    "            feature_tuple = UnidicFeaturesUnk(*feature_list)\n",
    "        \n",
    "        # ChaSen output format required by ChaOne:\n",
    "        # (OUTPUT_FORMAT \"<cha:W1 orth=\"%m\" pron=\"%?U/%m/%a0/\" pos=\"%U(%P-)\"%?T/ cType=\"%T \"//%?F/ cForm=\"%F \"//%?I/ %i0//>%m\\n\")\n",
    "\n",
    "        \n",
    "        # (OUTPUT_FORMAT \"<cha:W1 \n",
    "        word_element = etree.Element('W1')\n",
    "        # orth=\\\"%m\\\" \n",
    "        word_element.set('orth', str(surface))\n",
    "        # pron=\\\"%?U/%m/%a0/\\\" pos=\\\"%U(%P-)\\\"\n",
    "        if is_unk:\n",
    "            word_element.set('pron', str(surface))\n",
    "            word_element.set('pos', '未知語')\n",
    "        else:\n",
    "            word_element.set('pron', feature_tuple.pron)\n",
    "            pos = feature_tuple.pos1\n",
    "            if feature_tuple.pos2 != '*':\n",
    "                pos += '-' + feature_tuple.pos2\n",
    "                if feature_tuple.pos3 != '*':\n",
    "                    pos += '-' + feature_tuple.pos3\n",
    "                    if feature_tuple.pos4 != '*':\n",
    "                        pos += '-' + feature_tuple.pos4\n",
    "            word_element.set('pos', pos)\n",
    "        #%?T/ cType=\\\"%T \\\"//%?F/ cForm=\\\"%F \\\"//\n",
    "        if feature_tuple.cType is not None and feature_tuple.cType != '*':\n",
    "            word_element.set('cType', feature_tuple.cType)\n",
    "            word_element.set('cForm', feature_tuple.cForm)\n",
    "\n",
    "        #%?I/ %i0 ///>\\n\")\n",
    "        if feature_tuple.orthBase is not None and feature_tuple.orthBase != '*':\n",
    "            word_element.set('orthBase', feature_tuple.orthBase)\n",
    "        if feature_tuple.pronBase is not None and feature_tuple.pronBase != '*':\n",
    "            word_element.set('pronBase', feature_tuple.pronBase)\n",
    "\n",
    "        if feature_tuple.lForm is not None and feature_tuple.lForm != '*':\n",
    "            word_element.set('lForm', feature_tuple.lForm)\n",
    "        if feature_tuple.lemma is not None and feature_tuple.lemma != '*':\n",
    "            word_element.set('lForm', feature_tuple.lemma)\n",
    "        if feature_tuple.goshu is not None and feature_tuple.goshu != '*':\n",
    "            word_element.set('goshu', feature_tuple.goshu)\n",
    "        if feature_tuple.iType is not None and feature_tuple.iType != '*':\n",
    "            word_element.set('iType', feature_tuple.iType)\n",
    "        if feature_tuple.iForm is not None and feature_tuple.iForm != '*':\n",
    "            word_element.set('iForm', feature_tuple.iForm)\n",
    "        if feature_tuple.fType is not None and feature_tuple.fType != '*':\n",
    "            word_element.set('fType', feature_tuple.fType)\n",
    "        if feature_tuple.fForm is not None and feature_tuple.fForm != '*':\n",
    "            word_element.set('fForm', feature_tuple.fForm)\n",
    "        if feature_tuple.iConType is not None and feature_tuple.iConType != '*':\n",
    "            word_element.set('iConType', feature_tuple.iConType)\n",
    "        if feature_tuple.fConType is not None and feature_tuple.fConType != '*':\n",
    "            word_element.set('fConType', feature_tuple.fConType)\n",
    "        if feature_tuple.type is not None and feature_tuple.type != '*':\n",
    "            word_element.set('type', feature_tuple.type)\n",
    "\n",
    "        if feature_tuple.kana is not None and feature_tuple.kana != '*':\n",
    "            word_element.set('kana', feature_tuple.kana)\n",
    "        if feature_tuple.kanaBase is not None and feature_tuple.kanaBase != '*':\n",
    "            word_element.set('kanaBase', feature_tuple.kanaBase)\n",
    "\n",
    "        if feature_tuple.form is not None and feature_tuple.form != '*':\n",
    "            word_element.set('form', feature_tuple.form)\n",
    "        if feature_tuple.formBase is not None and feature_tuple.formBase != '*':\n",
    "            word_element.set('formBase', feature_tuple.formBase)\n",
    "\n",
    "        if feature_tuple.aType is not None and feature_tuple.aType != '*':\n",
    "            word_element.set('aType', feature_tuple.aType)\n",
    "        if feature_tuple.aConType is not None and feature_tuple.aConType != '*':\n",
    "            word_element.set('aConType', feature_tuple.aConType)\n",
    "        if feature_tuple.aModType is not None and feature_tuple.aModType != '*':\n",
    "            word_element.set('aModType', feature_tuple.aModType)\n",
    "\n",
    "        if feature_tuple.lid is not None and feature_tuple.lid != '*':\n",
    "            word_element.set('lid', feature_tuple.lid)\n",
    "        if feature_tuple.lemma_id is not None and feature_tuple.lemma_id != '*':\n",
    "            word_element.set('lemma_id', feature_tuple.lemma_id)\n",
    "\n",
    "        xml_tree.append(word_element)\n",
    "    return xml_tree\n",
    "\n",
    "def tagger_output_to_xml(words):\n",
    "    xml_tree = etree.Element('S')\n",
    "    for word in words:\n",
    "        # (OUTPUT_FORMAT \"<cha:W1 \n",
    "        word_element = etree.Element('W1')\n",
    "        # orth=\\\"%m\\\" \n",
    "        word_element.set('orth', str(word))\n",
    "        # pron=\\\"%?U/%m/%a0/\\\" pos=\\\"%U(%P-)\\\"\n",
    "        if word.is_unk:\n",
    "            word_element.set('pron', str(word))\n",
    "            word_element.set('pos', '未知語')\n",
    "        else:\n",
    "            word_element.set('pron', word.feature.pron)\n",
    "            pos = word.feature.pos1\n",
    "            if word.feature.pos2 != '*':\n",
    "                pos += '-' + word.feature.pos2\n",
    "                if word.feature.pos3 != '*':\n",
    "                    pos += '-' + word.feature.pos3\n",
    "                    if word.feature.pos4 != '*':\n",
    "                        pos += '-' + word.feature.pos4\n",
    "            word_element.set('pos', pos)\n",
    "        #%?T/ cType=\\\"%T \\\"//%?F/ cForm=\\\"%F \\\"//\n",
    "        if word.feature.cType is not None and word.feature.cType != '*':\n",
    "            word_element.set('cType', word.feature.cType)\n",
    "            word_element.set('cForm', word.feature.cForm)\n",
    "\n",
    "        #%?I/ %i0 ///>\\n\")\n",
    "        if word.feature.orthBase is not None and word.feature.orthBase != '*':\n",
    "            word_element.set('orthBase', word.feature.orthBase)\n",
    "        if word.feature.pronBase is not None and word.feature.pronBase != '*':\n",
    "            word_element.set('pronBase', word.feature.pronBase)\n",
    "\n",
    "        if word.feature.lForm is not None and word.feature.lForm != '*':\n",
    "            word_element.set('lForm', word.feature.lForm)\n",
    "        if word.feature.lemma is not None and word.feature.lemma != '*':\n",
    "            word_element.set('lForm', word.feature.lemma)\n",
    "        if word.feature.goshu is not None and word.feature.goshu != '*':\n",
    "            word_element.set('goshu', word.feature.goshu)\n",
    "        if word.feature.iType is not None and word.feature.iType != '*':\n",
    "            word_element.set('iType', word.feature.iType)\n",
    "        if word.feature.iForm is not None and word.feature.iForm != '*':\n",
    "            word_element.set('iForm', word.feature.iForm)\n",
    "        if word.feature.fType is not None and word.feature.fType != '*':\n",
    "            word_element.set('fType', word.feature.fType)\n",
    "        if word.feature.fForm is not None and word.feature.fForm != '*':\n",
    "            word_element.set('fForm', word.feature.fForm)\n",
    "        if word.feature.iConType is not None and word.feature.iConType != '*':\n",
    "            word_element.set('iConType', word.feature.iConType)\n",
    "        if word.feature.fConType is not None and word.feature.fConType != '*':\n",
    "            word_element.set('fConType', word.feature.fConType)\n",
    "        if word.feature.type is not None and word.feature.type != '*':\n",
    "            word_element.set('type', word.feature.type)\n",
    "\n",
    "        if word.feature.kana is not None and word.feature.kana != '*':\n",
    "            word_element.set('kana', word.feature.kana)\n",
    "        if word.feature.kanaBase is not None and word.feature.kanaBase != '*':\n",
    "            word_element.set('kanaBase', word.feature.kanaBase)\n",
    "\n",
    "        if word.feature.form is not None and word.feature.form != '*':\n",
    "            word_element.set('form', word.feature.form)\n",
    "        if word.feature.formBase is not None and word.feature.formBase != '*':\n",
    "            word_element.set('formBase', word.feature.formBase)\n",
    "\n",
    "        if word.feature.aType is not None and word.feature.aType != '*':\n",
    "            word_element.set('aType', word.feature.aType)\n",
    "        if word.feature.aConType is not None and word.feature.aConType != '*':\n",
    "            word_element.set('aConType', word.feature.aConType)\n",
    "        if word.feature.aModType is not None and word.feature.aModType != '*':\n",
    "            word_element.set('aModType', word.feature.aModType)\n",
    "\n",
    "        if word.feature.lid is not None and word.feature.lid != '*':\n",
    "            word_element.set('lid', word.feature.lid)\n",
    "        if word.feature.lemma_id is not None and word.feature.lemma_id != '*':\n",
    "            word_element.set('lemma_id', word.feature.lemma_id)\n",
    "\n",
    "        xml_tree.append(word_element)\n",
    "    return xml_tree\n",
    "\n",
    "def split_mora(kana_string):\n",
    "    mora_list = []\n",
    "    vowel_deleters = {'ャ', 'ュ', 'ョ', 'ァ', 'ィ', 'ゥ', 'ェ', 'ォ'}\n",
    "    for i in range(0, len(kana_string)):\n",
    "        if i > 0 and kana_string[i] in vowel_deleters and mora_list[-1][-1] != kana_string[i]:\n",
    "            mora_list[-1] = mora_list[-1] + kana_string[i]\n",
    "        else:\n",
    "            mora_list.append(kana_string[i])\n",
    "    return mora_list\n",
    "    \n",
    "def transformed_tree_to_annotated_kana(tree):\n",
    "    annotated_string = ''\n",
    "    current_pitch_level = 'L'\n",
    "    for ap in tree.getroot():\n",
    "        if ap.get('pron') == '*':\n",
    "            annotated_string += ap.get('orth') + ' '\n",
    "        else:\n",
    "            accented_mora = int(ap.get('aType'))\n",
    "            mora_from_ap_start = 0\n",
    "            if accented_mora == 1 and current_pitch_level == 'L':\n",
    "                annotated_string += '↗'\n",
    "                current_pitch_level = 'H'\n",
    "            for w2 in ap:\n",
    "                word_pron = w2.get('pron')\n",
    "                if accented_mora == 0:\n",
    "                    if current_pitch_level == 'H' or w2.get('pos')[0:3] == '助動詞':\n",
    "                        annotated_string += word_pron + ' ' \n",
    "                    else:\n",
    "                        mora_list = split_mora(word_pron)\n",
    "                        annotated_string += mora_list[0] + '↗' + ''.join(mora_list[1:])\n",
    "                        current_pitch_level = 'H'\n",
    "                else:\n",
    "                    mora_list = split_mora(word_pron)\n",
    "                    for mora in mora_list:\n",
    "                        annotated_string += mora\n",
    "                        mora_from_ap_start += 1\n",
    "                        if mora_from_ap_start == 1 and current_pitch_level == 'L':\n",
    "                            annotated_string += '↗'\n",
    "                            current_pitch_level = 'H'\n",
    "                        if mora_from_ap_start == accented_mora:\n",
    "                            annotated_string += '↘'\n",
    "                            current_pitch_level = 'L'\n",
    "                    annotated_string += ' '\n",
    "    return annotated_string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↗ボ↘ク ガ サ↗イショニ ヨ↘ン ダ ニ↗ホンゴチョーヘンショ↘ーセツ ワ ヨ↗シモトバ↘ナナ ノ 「 ↗キ↘ッチン 」 ダ 。 タ↗ンペンショ↘ーセツ ワ ム↗ラカミハ↘ルキ ノ サ↗クヒンオ ケッコー ヨン デ イル↘ ケド 、\n",
      "ニ↗ッポ↘ンゴ ノ ショ↗ーセツワ アマリ ヨン デ イ ナイ 。 ニチエーホンヤク↘シャ ト シ↗テ コノ ママ↘ デ ↗イ↘ー ノ カ ナ …\n"
     ]
    }
   ],
   "source": [
    "text1 = \"\"\"僕が最初に読んだ日本語長編小説は吉本ばななの「キッチン」だ。\n",
    "短編小説は村上春樹の作品を決行読んでいるけど、\"\"\"\n",
    "text2 = \"\"\"日本語の小説はあまり読んでいない。\n",
    "日英翻訳者としてこのままでいいのかな…\"\"\"\n",
    "print(annotate_accent(text1))\n",
    "print(annotate_accent(text2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['日本\\t名詞,固有名詞,地名,国,,,ニッポン,日本,日本,ニッポン,日本,ニッポン,固,,,,,,,国,ニッポン,ニッポン,ニッポン,ニッポン,3,,,7821659499274752,28455', '語\\t名詞,普通名詞,一般,,,,ゴ,語,語,ゴ,語,ゴ,漢,,,,,,,体,ゴ,ゴ,ゴ,ゴ,1,C3,,3665230634820096,13334']\n",
      "['日本\\t名詞,固有名詞,地名,国,,,ニッポン,日本,日本,ニホン,日本,ニホン,固,,,,,,,国,ニホン,ニホン,ニホン,ニホン,2,,,7821668089209344,28455', '語\\t名詞,普通名詞,一般,,,,ゴ,語,語,ゴ,語,ゴ,漢,,,,,,,体,ゴ,ゴ,ゴ,ゴ,1,C3,,3665230634820096,13334']\n",
      "['日本\\t名詞,固有名詞,地名,国,,,ニッポン,日本,日本,ニポン,日本,ニポン,固,,,,,,,国,ニポン,ニポン,ニポン,ニポン,2,,,7821676679143936,28455', '語\\t名詞,普通名詞,一般,,,,ゴ,語,語,ゴ,語,ゴ,漢,,,,,,,体,ゴ,ゴ,ゴ,ゴ,1,C3,,3665230634820096,13334']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ニ↗ッポ↘ンゴ', 'ニ↗ホ↘ンゴ', 'ニ↗ポ↘ンゴ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotate_accent_nbest(\"日本語\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (OUTPUT_FORMAT \"<cha:W1 orth=\\\"%m\\\" pron=\\\"%?U/%m/%a0/\\\" \\\n",
    "pos=\\\"%U(%P-)\\\"%?T/ cType=\\\"%T \\\"//%?F/ cForm=\\\"%F \\\"//%?I/ %i0 \\\n",
    "//>%m</cha:W1>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
